<div align="center">

<img src="assets/logo.svg" alt="PromptMill" width="320">

<br/>

**AI-powered prompt generator for video, image, and creative content**

[![Python 3.11+](https://img.shields.io/badge/Python-3.11+-3776AB?style=flat-square&logo=python&logoColor=white)](https://python.org)
[![Gradio](https://img.shields.io/badge/Gradio-4.x-FF6F00?style=flat-square&logo=gradio&logoColor=white)](https://gradio.app)
[![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?style=flat-square&logo=docker&logoColor=white)](https://docker.com)
[![Ruff](https://img.shields.io/badge/Ruff-Linted-D7FF64?style=flat-square&logo=ruff&logoColor=black)](https://docs.astral.sh/ruff/)
[![License: MIT](https://img.shields.io/badge/License-MIT-22c55e?style=flat-square)](LICENSE)
[![GitHub stars](https://img.shields.io/github/stars/kekzl/PromptMill?style=flat-square&logo=github)](https://github.com/kekzl/PromptMill)

[Features](#-features) Â· [Quick Start](#-quick-start) Â· [Supported Targets](#-supported-targets) Â· [Models](#-llm-options) Â· [Configuration](#%EF%B8%8F-configuration)

</div>

---

## Overview

PromptMill is a self-contained web UI that runs **entirely locally** - no API keys, no cloud dependencies. It uses selectable LLMs (scaled by your GPU VRAM) to generate optimized prompts for the latest AI video and image generators.

<div align="center">
<table>
<tr>
<td align="center"><b>34</b><br><sub>Preset Roles</sub></td>
<td align="center"><b>7</b><br><sub>LLM Options</sub></td>
<td align="center"><b>0.5B-14B</b><br><sub>Parameters</sub></td>
<td align="center"><b>100%</b><br><sub>Local</sub></td>
</tr>
</table>
</div>

---

## âœ¨ Features

- **Smart GPU Detection** - Automatically selects the best model for your VRAM
- **7 LLM Tiers** - From 0.5B (CPU) to 14B parameters (24GB+ VRAM)
- **34 Specialized Roles** - Video, image, audio, 3D, and creative
- **Dark Mode UI** - Modern interface with streaming generation
- **Model Cleanup** - Delete downloaded models to free disk space
- **Zero Config** - Works out of the box with Docker
- **Fully Offline** - No API keys or internet required after setup

---

## ğŸš€ Quick Start

### Docker (Recommended)

```bash
# GPU (NVIDIA) - auto-detects VRAM
docker compose --profile gpu up -d

# CPU only
docker compose --profile cpu up -d
```

Open **http://localhost:7610**

> Models auto-download on first use and persist in `./models/`

### Manual Installation

```bash
# GPU (CUDA)
CMAKE_ARGS="-DGGML_CUDA=on" pip install llama-cpp-python
pip install gradio huggingface_hub
python app.py

# CPU only
pip install llama-cpp-python gradio huggingface_hub
python app.py
```

---

## ğŸ¯ Supported Targets

<table>
<tr>
<td width="50%">

### ğŸ¬ Video (10)
Wan2.1, Wan2.2, Hunyuan Video, Hunyuan 1.5, Runway Gen-3, Kling AI, Pika Labs, Luma Dream Machine, Sora, Veo

### ğŸ–¼ï¸ Image (10)
Stable Diffusion, Midjourney, FLUX, DALL-E 3, ComfyUI, Ideogram, Leonardo AI, Adobe Firefly, Recraft, Imagen 3

</td>
<td width="50%">

### ğŸ”Š Audio (3)
Suno AI, Udio, ElevenLabs

### ğŸ§Š 3D (2)
Meshy, Tripo AI

### âœï¸ Creative (9)
Story Writer, Code Generator, Technical Writer, Marketing Copy, SEO Content, Screenplay Writer, Social Media Manager, Video Script Writer, Song Lyrics

</td>
</tr>
</table>

---

## ğŸ§  LLM Options

PromptMill automatically selects the best model based on your GPU:

| VRAM | Model | Size | Quality |
|:-----|:------|:-----|:--------|
| CPU | Qwen2.5 0.5B Q8 | ~1GB | â­ |
| 4GB | Qwen2.5 1.5B Q4 | ~2GB | â­â­ |
| 6GB | Qwen2.5 3B Q4 | ~4GB | â­â­â­ |
| 8GB | Dolphin Mistral 7B Q4 | ~6GB | â­â­â­â­ |
| 12GB | Qwen2.5 7B Q6 | ~10GB | â­â­â­â­ |
| 16GB+ | Qwen2.5 14B Q4 | ~12GB | â­â­â­â­â­ |
| 24GB+ | Qwen2.5 14B Q8 | ~18GB | â­â­â­â­â­ |

---

## âš™ï¸ Configuration

The app auto-configures based on your hardware:

- **GPU detected** â†’ Uses all layers on GPU, selects model by VRAM
- **No GPU** â†’ CPU mode with lightweight 0.5B model

Manual override available in the UI for GPU layers and model selection.

---

## ğŸ“ Project Structure

```
PromptMill/
â”œâ”€â”€ app.py              # Main application
â”œâ”€â”€ pyproject.toml      # Project config & dependencies
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ logo.svg        # Logo
â”œâ”€â”€ Dockerfile.gpu      # CUDA build
â”œâ”€â”€ Dockerfile.cpu      # CPU build
â”œâ”€â”€ docker-compose.yml  # Docker orchestration
â””â”€â”€ models/             # Downloaded LLMs (persisted)
```

---

## ğŸ› ï¸ Development

Requires [uv](https://docs.astral.sh/uv/) (recommended) or pip.

```bash
# Install dependencies
uv sync

# Run with uv
uv run python app.py

# Lint & format
uv run ruff check --fix
uv run ruff format
```

---

## ğŸ¤ Contributing

Contributions welcome! Feel free to:
- Report bugs or request features via [Issues](https://github.com/kekzl/PromptMill/issues)
- Submit pull requests

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

---

<div align="center">

**[â¬† Back to top](#)**

Made with â¤ï¸ for the AI creative community

</div>
