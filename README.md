<div align="center">

<img src="assets/logo.svg" alt="PromptMill" width="320">

<br/>

**AI-powered prompt generator for video, image, and creative content**

[![Python 3.11+](https://img.shields.io/badge/Python-3.11+-3776AB?style=flat-square&logo=python&logoColor=white)](https://python.org)
[![Gradio](https://img.shields.io/badge/Gradio-4.x-FF6F00?style=flat-square&logo=gradio&logoColor=white)](https://gradio.app)
[![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?style=flat-square&logo=docker&logoColor=white)](https://docker.com)
[![Ruff](https://img.shields.io/badge/Ruff-Linted-D7FF64?style=flat-square&logo=ruff&logoColor=black)](https://docs.astral.sh/ruff/)
[![License: MIT](https://img.shields.io/badge/License-MIT-22c55e?style=flat-square)](LICENSE)
[![GitHub stars](https://img.shields.io/github/stars/kekzl/PromptMill?style=flat-square&logo=github)](https://github.com/kekzl/PromptMill)

[Features](#-features) ¬∑ [Quick Start](#-quick-start) ¬∑ [Supported Targets](#-supported-targets) ¬∑ [Models](#-llm-options) ¬∑ [Configuration](#%EF%B8%8F-configuration)

</div>

---

## Overview

PromptMill is a self-contained web UI that runs **entirely locally** - no API keys, no cloud dependencies. It uses selectable LLMs (scaled by your GPU VRAM) to generate optimized prompts for the latest AI video and image generators.

<div align="center">
<table>
<tr>
<td align="center"><b>14</b><br><sub>Preset Roles</sub></td>
<td align="center"><b>7</b><br><sub>LLM Options</sub></td>
<td align="center"><b>0.5B-14B</b><br><sub>Parameters</sub></td>
<td align="center"><b>100%</b><br><sub>Local</sub></td>
</tr>
</table>
</div>

---

## ‚ú® Features

- **Smart GPU Detection** - Automatically selects the best model for your VRAM
- **7 LLM Tiers** - From 0.5B (CPU) to 14B parameters (24GB+ VRAM)
- **14 Specialized Roles** - Optimized prompts for each target AI
- **Dark Mode UI** - Modern interface with streaming generation
- **Model Cleanup** - Delete downloaded models to free disk space
- **Zero Config** - Works out of the box with Docker
- **Fully Offline** - No API keys or internet required after setup

---

## üöÄ Quick Start

### Docker (Recommended)

```bash
# GPU (NVIDIA) - auto-detects VRAM
docker compose --profile gpu up -d

# CPU only
docker compose --profile cpu up -d
```

Open **http://localhost:7610**

> Models auto-download on first use and persist in `./models/`

### Manual Installation

```bash
# GPU (CUDA)
CMAKE_ARGS="-DGGML_CUDA=on" pip install llama-cpp-python
pip install gradio huggingface_hub
python app.py

# CPU only
pip install llama-cpp-python gradio huggingface_hub
python app.py
```

---

## üéØ Supported Targets

<table>
<tr>
<td width="33%">

### üé¨ Video
- **Wan2.1** - Cinematic text-to-video
- **Wan2.2** - Enhanced motion & physics
- **Hunyuan Video** - Tencent T2V
- **Hunyuan 1.5** - Extended duration + I2V

</td>
<td width="33%">

### üñºÔ∏è Image
- **Stable Diffusion** - SD/SDXL
- **Midjourney** - Artistic style
- **FLUX** - Black Forest Labs
- **DALL-E 3** - OpenAI
- **ComfyUI** - Workflow prompts

</td>
<td width="33%">

### ‚úçÔ∏è Creative
- **Story Writer** - Narratives
- **Code Generator** - Programming
- **Technical Writer** - Docs
- **Marketing Copy** - Ads & CTAs
- **SEO Content** - Blog posts

</td>
</tr>
</table>

---

## üß† LLM Options

PromptMill automatically selects the best model based on your GPU:

| VRAM | Model | Size | Quality |
|:-----|:------|:-----|:--------|
| CPU | Qwen2.5 0.5B Q8 | ~1GB | ‚≠ê |
| 4GB | Qwen2.5 1.5B Q4 | ~2GB | ‚≠ê‚≠ê |
| 6GB | Qwen2.5 3B Q4 | ~4GB | ‚≠ê‚≠ê‚≠ê |
| 8GB | Dolphin Mistral 7B Q4 | ~6GB | ‚≠ê‚≠ê‚≠ê‚≠ê |
| 12GB | Qwen2.5 7B Q6 | ~10GB | ‚≠ê‚≠ê‚≠ê‚≠ê |
| 16GB+ | Qwen2.5 14B Q4 | ~12GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| 24GB+ | Qwen2.5 14B Q8 | ~18GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |

---

## ‚öôÔ∏è Configuration

The app auto-configures based on your hardware:

- **GPU detected** ‚Üí Uses all layers on GPU, selects model by VRAM
- **No GPU** ‚Üí CPU mode with lightweight 0.5B model

Manual override available in the UI for GPU layers and model selection.

---

## üìÅ Project Structure

```
PromptMill/
‚îú‚îÄ‚îÄ app.py              # Main application
‚îú‚îÄ‚îÄ pyproject.toml      # Project config & dependencies
‚îú‚îÄ‚îÄ assets/
‚îÇ   ‚îî‚îÄ‚îÄ logo.svg        # Logo
‚îú‚îÄ‚îÄ Dockerfile.gpu      # CUDA build
‚îú‚îÄ‚îÄ Dockerfile.cpu      # CPU build
‚îú‚îÄ‚îÄ docker-compose.yml  # Docker orchestration
‚îî‚îÄ‚îÄ models/             # Downloaded LLMs (persisted)
```

---

## üõ†Ô∏è Development

Requires [uv](https://docs.astral.sh/uv/) (recommended) or pip.

```bash
# Install dependencies
uv sync

# Run with uv
uv run python app.py

# Lint & format
uv run ruff check --fix
uv run ruff format
```

---

## ü§ù Contributing

Contributions welcome! Feel free to:
- Report bugs or request features via [Issues](https://github.com/kekzl/PromptMill/issues)
- Submit pull requests

---

## üìÑ License

MIT License - see [LICENSE](LICENSE) for details.

---

<div align="center">

**[‚¨Ü Back to top](#)**

Made with ‚ù§Ô∏è for the AI creative community

</div>
