# PromptMill - CPU Build
# AI Prompt Generator with local LLM

FROM python:3.12-slim-bookworm

ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1

# Install build dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    cmake \
    git \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Upgrade pip
RUN pip install --no-cache-dir --upgrade pip

# Install Python dependencies (CPU-only llama-cpp-python)
RUN pip install --no-cache-dir \
    "huggingface_hub>=0.20.0,<1.0.0" \
    "gradio>=4.44.0,<5.0.0" \
    "pytest>=7.0.0" \
    "pytest-cov>=4.0.0"

# Install llama-cpp-python without CUDA
RUN pip install --no-cache-dir llama-cpp-python

# Create non-root user for security
RUN useradd -m -s /bin/bash -u 1000 promptmill

COPY --chown=promptmill:promptmill src/ ./src/
COPY --chown=promptmill:promptmill assets/ ./assets/
COPY --chown=promptmill:promptmill tests/ ./tests/

# Create models directory and set ownership of entire app directory
RUN mkdir -p /app/models && chown -R promptmill:promptmill /app
ENV MODELS_DIR=/app/models
ENV HF_HOME=/app/models/.cache
ENV PYTHONPATH=/app/src

# Switch to non-root user
USER promptmill

EXPOSE 7610

# Health check using /health endpoint
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD python -c "import urllib.request; urllib.request.urlopen('http://localhost:7610/health')" || exit 1

CMD ["python", "-m", "promptmill"]
